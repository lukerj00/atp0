# Milestone 4 — Planning + Lemma Decomposition (“Plan → Prove → Refine” Blueprint Loop)

## Goal
Upgrade the system from “direct proof attempts” to an **Aleph-like** workflow by adding a **Plan phase** that proposes a **proof blueprint** (lemma decomposition), and a **Refine phase** that can **edit the blueprint** when branches fail.

Milestone 4 produces the first real “agentic ATP” structure:
- **Plan:** propose intermediate lemmas and a proof skeleton
- **Prove:** discharge lemmas + main theorem via LeanWorker verification loop
- **Refine:** backtrack and adjust lemmas/structure based on failures

**No training.** Planning is done via Model Gateway calls + retrieval + heuristics.

---

## Dependencies
- Milestone 1: LeanWorker verifier service
- Milestone 2: Orchestrator direct proving + repair loop + cache
- Milestone 3: Retriever service + RAG integration in prompts

---

## Scope (what to build)

### Deliverables
1. A **Blueprint** data model:
   - lemmas list (Lean statements)
   - a dependency structure (V0: simple ordering; optional DAG edges)
   - proof hints/tags per lemma
2. A **Planner interface** in Model Gateway:
   - `plan(problem, retrieved_context, failure_summary) -> Blueprint`
3. Orchestrator changes:
   - Plan once → attempt to prove lemmas → attempt to prove main theorem using proved lemmas
   - if failure: refine blueprint (edit) and retry for a limited number of blueprint iterations
4. A **lemma library file** generation strategy:
   - keep proved lemmas in the same Lean file or separate files
   - ensure main theorem can import/use them
5. Search policy:
   - blueprint-level beam (keep top K blueprints) OR single-best blueprint with refinement
   - V0: single blueprint + limited refinement iterations is acceptable
6. Logs/artifacts showing:
   - blueprint versions
   - which lemmas proved, failed, reused
   - final proof file if success

---

## Non-goals (Milestone 4)
- No full MCTS over blueprint edits (beam + refine is enough)
- No interactive goal-state REPL
- No massive parallel lemma DAG scheduling (keep small)
- No automatic semantic correctness checks beyond Lean verification

---

## Blueprint Data Model

### Blueprint JSON schema (Planner output)
```json
{
  "blueprint_id": "string",
  "strategy": "direct|lemma_chain|case_split|induction",
  "lemmas": [
    {
      "name": "L1",
      "statement": "∀ n : Nat, ...",
      "hint_tags": ["simp", "induction"],
      "uses": ["L2"]   // optional dependencies by name
    }
  ],
  "main_hint": {
    "hint_tags": ["simp", "aesop"],
    "notes": "optional text"
  }
}
Constraints on Planner output (important)
Max lemmas: <= 6 in V0 (to control search explosion)

Lemma statements must be valid Lean propositions (no proof, just statements)

Lemma names must be unique and valid Lean identifiers

If uses is omitted: assume lemmas are independent or order as given

Planner Interface (Model Gateway)
Add a new method:

python
Copy code
def plan(problem: ProverInput, retrieved: RetrievedContext, failure_summary: FailureSummary | None) -> Blueprint:
    """Return a lemma decomposition blueprint for proving the theorem."""
Planner Prompt Requirements
Planner prompt must:

restate the target theorem

include retrieved mathlib declarations

include failure summary if refining

instruct the model to:

propose 0–6 lemmas

keep lemmas “useful and provable”

avoid invented library facts when possible

return JSON only, matching schema

Failure Summary (input to refinement)
Define a compact summary object generated by Orchestrator after a failed attempt:

json
Copy code
{
  "failed_goal": "main|lemma:L3",
  "error_class": "tactic_failed|type_mismatch|unknown_identifier|timeout|unsolved_goals|other",
  "message_excerpt": "string",
  "top_failed_candidates": [
    { "proof": "by ...", "error_class": "...", "message_excerpt": "..." }
  ],
  "retrieval_queries_used": ["..."],
  "tokens_from_errors": ["..."]
}
Use this summary as context for plan() refinement prompts.

Orchestrator: Blueprint Execution
High-level algorithm
Parameters:

blueprint_iterations (default 3)

lemma_budget (attempt rounds/checks per lemma)

main_budget (attempt rounds/checks for main theorem)

Algorithm:

Retrieve context for theorem.

blueprint = plan(problem, retrieved, failure_summary=None)

For iteration in 1..blueprint_iterations:

Attempt to prove all lemmas in blueprint:

schedule in order or topological order if dependencies exist

cache lemma proofs by statement hash

stop early if too many lemmas fail (threshold)

If all required lemmas proved (or optional ones skipped):

attempt main theorem proof, including proved lemmas in context

If success: return proof + blueprint + lemma proofs artifact

If failure:

produce failure_summary

update retrieved context using error tokens

call plan(problem, retrieved, failure_summary) to get revised blueprint

continue

Return failure report if all iterations exhausted.

Representing proved lemmas so the main theorem can use them
Choice (recommended V0): single-file “local lemma library”
When proving the main theorem, generate a Lean file:

lean
Copy code
import Mathlib

-- proved lemmas (as local theorems)
theorem L1 : <stmt> := by
  <proof>

theorem L2 : <stmt> := by
  <proof>

theorem T : <main_stmt> := by
  -- proof can now `have`/`exact`/`simp [L1, L2]` etc.
Implementation approach:

After each lemma proof succeeds, store its exact proof block.

For main theorem attempts, include all proved lemma declarations above T.

This allows the model to reference L1 etc. without extra imports.

Alternative (not required now): multi-file lemma artifacts
Separate files per lemma, import them into main theorem file

More scalable but more plumbing; skip in V0.

Prompting: how the prover uses the blueprint
Update prover/repair prompts to include:

Blueprint strategy

Lemma list + statements

Which lemmas are proved and their names

Instruction: prefer using proved lemmas by name (e.g., simp [L1, L2])

Example context block:

yaml
Copy code
# Blueprint
Strategy: lemma_chain
Available proved lemmas:
- L1 : ...
- L2 : ...
You may use these lemmas by name in your proof.
Search policy (V0 choice)
V0 recommended policy: single blueprint + refinement
Keep 1 blueprint at a time

Refine up to 3 iterations

This is simplest and still powerful

Optional upgrade: blueprint beam
If implementing beam:

keep top K blueprints (K=2 or 3)

score blueprint by:

number of lemmas proven

cost spent

main theorem progress

expand/refine best blueprint first

Not required for V0; implement only if easy.

Caching upgrades
Add caches for:

Lemma proof results keyed by lemma statement hash

Blueprint attempts keyed by:

theorem statement hash

retrieval context hash

failure_summary hash

Store:

best blueprint found so far for a theorem

lemma proofs reusable across jobs (optional, controlled by config)

Acceptance tests (Milestone 4)
Required test cases
A theorem that benefits from a simple intermediate lemma (e.g., rewriting lemma)

A theorem where direct proof fails but lemma decomposition succeeds

A failure case that triggers refinement (planner modifies lemma)

Required assertions
Orchestrator response includes:

blueprint used (and versions if refined)

lemma proof artifacts for proved lemmas

For at least one test, confirm:

lemma(s) proved first

main theorem proof references lemma name(s)

Definition of Done
plan() is implemented in Model Gateway and wired to Orchestrator

Blueprint execution loop proves lemmas and then main theorem in a single Lean file

Refinement loop triggers on failure and updates blueprint at least once

Logs/artifacts show blueprint versions and lemma proof statuses

At least one benchmark improves over Milestone 2/3 (direct proof only)

Notes for Milestone 5+
Add blueprint beam search

Add stepwise tactic REPL proof mode for more efficient refinement

Add more sophisticated dependency extraction / topological scheduling

Add import suggestions from retrieval and from Lean errors

makefile
Copy code
::contentReference[oaicite:0]{index=0}